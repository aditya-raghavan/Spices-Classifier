{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import keras, os\r\n",
                "from keras.models import Sequential\r\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\r\n",
                "from keras.preprocessing.image import ImageDataGenerator\r\n",
                "import numpy as np"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "trdata = ImageDataGenerator()\r\n",
                "traindata = trdata.flow_from_directory(directory=\"data/train\",target_size=(224,224))\r\n",
                "tsdata = ImageDataGenerator()\r\n",
                "testdata = tsdata.flow_from_directory(directory=\"data/test\", target_size=(224,224))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Found 110 images belonging to 2 classes.\n",
                        "Found 20 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "model = Sequential()\r\n",
                "\r\n",
                "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "model.add(Flatten())\r\n",
                "\r\n",
                "model.add(Dense(units=4096,activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Dense(units=4096,activation=\"relu\"))\r\n",
                "\r\n",
                "model.add(Dense(units=2, activation=\"softmax\"))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "from tensorflow.keras.optimizers import Adam\r\n",
                "\r\n",
                "opt = Adam(learning_rate=0.001)\r\n",
                "\r\n",
                "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "model.summary()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"sequential\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
                        "_________________________________________________________________\n",
                        "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
                        "_________________________________________________________________\n",
                        "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
                        "_________________________________________________________________\n",
                        "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
                        "_________________________________________________________________\n",
                        "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
                        "_________________________________________________________________\n",
                        "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
                        "_________________________________________________________________\n",
                        "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
                        "_________________________________________________________________\n",
                        "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
                        "_________________________________________________________________\n",
                        "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
                        "_________________________________________________________________\n",
                        "flatten (Flatten)            (None, 25088)             0         \n",
                        "_________________________________________________________________\n",
                        "dense (Dense)                (None, 4096)              102764544 \n",
                        "_________________________________________________________________\n",
                        "dense_1 (Dense)              (None, 4096)              16781312  \n",
                        "_________________________________________________________________\n",
                        "dense_2 (Dense)              (None, 2)                 8194      \n",
                        "=================================================================\n",
                        "Total params: 134,268,738\n",
                        "Trainable params: 134,268,738\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
                "from PIL import Image\r\n",
                "\r\n",
                "metric = 'val_accuracy'\r\n",
                "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor=metric, verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\r\n",
                "\r\n",
                "early = EarlyStopping(monitor=metric, min_delta=0, patience=20, verbose=1, mode='auto')\r\n",
                "\r\n",
                "# hist = model.fit_generator(steps_per_epoch=100, generator=traindata, validation_data=testdata, validation_steps=10, epochs=100, callbacks=[checkpoint, early])\r\n",
                "hist = model.fit(traindata, steps_per_epoch=100, epochs=100, validation_data=testdata, validation_steps=10, callbacks=[checkpoint, early])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.plot(hist.history[\"acc\"])\r\n",
                "plt.plot(hist.history['val_acc'])\r\n",
                "plt.plot(hist.history['loss'])\r\n",
                "plt.plot(hist.history['val_loss'])\r\n",
                "plt.title(\"model accuracy\")\r\n",
                "plt.ylabel(\"Accuracy\")\r\n",
                "plt.xlabel(\"Epoch\")\r\n",
                "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from keras.preprocessing import image\r\n",
                "\r\n",
                "img = image.load_img(\"image.jpg\",target_size=(224,224))\r\n",
                "img = np.asarray(img)\r\n",
                "plt.imshow(img)\r\n",
                "img = np.expand_dims(img, axis=0)\r\n",
                "\r\n",
                "from keras.models import load_model\r\n",
                "saved_model = load_model(\"vgg16_1.h5\")\r\n",
                "\r\n",
                "output = saved_model.predict(img)\r\n",
                "if output[0][0] > output[0][1]:\r\n",
                "    print(\"chilli\")\r\n",
                "else:\r\n",
                "    print('turmeric')"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.0 64-bit ('.env': venv)"
        },
        "interpreter": {
            "hash": "c4a55edef579968ae1ac8731b983344f279712eafd12fc066617506f448616b4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}